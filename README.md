# ğŸ¦ Twitter Real-Time Analysis Pipeline

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Kafka](https://img.shields.io/badge/Kafka-3.6-red.svg)](https://kafka.apache.org)
[![Docker](https://img.shields.io/badge/Docker-required-blue.svg)](https://docker.com)

SystÃ¨me d'analyse de tweets en temps rÃ©el utilisant Kafka, OpenAI, Elasticsearch, Cassandra et Kibana.

## ğŸ¯ Objectifs du projet

Analyser des tweets en temps rÃ©el pour extraire :
- âœ… Les hashtags les plus utilisÃ©s
- âœ… Les statistiques des sentiments (positif/nÃ©gatif/neutre)
- âœ… Les mots les plus frÃ©quents
- âœ… Les meilleurs et pires tweets
- âœ… Visualisations interactives avec Kibana

---

## ğŸ—ï¸ Architecture
```
[Twitter API] 
    â†“
[Kafka Producer] â†’ [Topic: tweets_raw]
    â†“
[Kafka Consumer]
    â†“
[OpenAI API] (analyse sentiment + topics)
    â†“
[Elasticsearch] (indexation + recherche)
    â†“
[Cassandra] (stockage permanent)
    â†“
[Kibana] (visualisation + dashboards)
```

**SchÃ©ma dÃ©taillÃ© :** Voir [docs/architecture.md](docs/architecture.md)

---

## ğŸ‘¥ Ã‰quipe & ResponsabilitÃ©s

| Membre | OS | Composants | Dossiers |
|--------|----|-----------|-----------------------|
| **Personne 1** | Linux | Kafka + Twitter Stream | `producer/`, `consumer/`, `data/` |
| **Personne 2** | Linux | OpenAI + Elasticsearch | `analysis/` |
| **Personne 3** | Windows | Cassandra + Kibana | `storage/`, `dashboards/` |

---

## ğŸš€ Installation & Setup

### PrÃ©requis

- **Python 3.8+**
- **Docker & Docker Compose**
- **Compte dÃ©veloppeur Twitter** ([developer.twitter.com](https://developer.twitter.com))
- **ClÃ© API OpenAI** (pour Personne 2)

### Setup rapide
```bash
# 1. Cloner le repo
git clone https://github.com/votre-username/Twitter-Project.git
cd Twitter-Project

# 2. CrÃ©er l'environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
cp .env.example .env
nano .env  # Ajouter vos clÃ©s API

# 5. Lancer Docker (Kafka, Elasticsearch, Kibana, Cassandra)
docker-compose up -d

# 6. VÃ©rifier que tous les services sont UP
docker-compose ps
```

---

## ğŸ® Utilisation

### Terminal 1 : Lancer le Producer (Twitter â†’ Kafka)
```bash
source venv/bin/activate
cd producer/
python twitter_stream_producer.py
```

### Terminal 2 : Lancer le Consumer (Kafka â†’ Analyse)
```bash
source venv/bin/activate
cd consumer/
python consumer.py
```

### Terminal 3 : Analyse OpenAI (Personne 2)
```bash
source venv/bin/activate
cd analysis/
python openai_analyzer.py
```

---

## ğŸ“Š AccÃ¨s aux interfaces

| Service | URL | Description |
|---------|-----|-------------|
| **Kibana** | http://localhost:5601 | Dashboards & visualisations |
| **Elasticsearch** | http://localhost:9200 | API REST pour requÃªtes |
| **Kafka** | localhost:9092 | Broker Kafka |
| **Cassandra** | localhost:9042 | Base de donnÃ©es NoSQL |

---

## ğŸ“ Structure du projet
```
Twitter-Project/
â”œâ”€â”€ producer/          # Stream Twitter â†’ Kafka
â”œâ”€â”€ consumer/          # Kafka â†’ Processing
â”œâ”€â”€ analysis/          # OpenAI + Elasticsearch (Personne 2)
â”œâ”€â”€ storage/           # Cassandra setup (Personne 3)
â”œâ”€â”€ dashboards/        # Kibana dashboards (Personne 3)
â”œâ”€â”€ data/              # Datasets & samples
â”œâ”€â”€ docs/              # Documentation technique
â””â”€â”€ tests/             # Tests unitaires
```

**Voir les README spÃ©cifiques dans chaque dossier pour plus de dÃ©tails.**

---

## ğŸ”§ Configuration

### Variables d'environnement (.env)
```bash
# Twitter API
TWITTER_BEARER_TOKEN=your_token_here
TWITTER_API_KEY=your_key_here
TWITTER_API_SECRET=your_secret_here

# Kafka
KAFKA_BROKER=localhost:9092
KAFKA_TOPIC_RAW=tweets_raw
KAFKA_TOPIC_ANALYZED=tweets_analyzed

# OpenAI (Personne 2)
OPENAI_API_KEY=your_openai_key_here

# Elasticsearch
ELASTICSEARCH_HOST=localhost:9200

# Cassandra
CASSANDRA_HOST=localhost:9042
```

**âš ï¸ Ne jamais commit le fichier `.env` ! Utilisez `.env.example` comme template.**

---

## ğŸ“š Documentation

- [Architecture dÃ©taillÃ©e](docs/architecture.md)
- [SchÃ©ma JSON](docs/schema.json)
- [Guide de setup complet](docs/setup-guide.md)
- [Producer README](producer/README.md)
- [Consumer README](consumer/README.md)
- [Analysis README](analysis/README.md)

---

## ğŸ§ª Tests
```bash
# Tester la connexion Twitter
python producer/test_twitter.py

# Tester Kafka
python tests/test_kafka.py

# Tester Elasticsearch
python tests/test_elasticsearch.py
```

---

## ğŸ› DÃ©pannage

### Kafka ne dÃ©marre pas
```bash
docker-compose down
docker-compose up -d
docker logs kafka
```

### Tweets n'arrivent pas
- VÃ©rifier le Bearer Token dans `.env`
- VÃ©rifier les rÃ¨gles de filtrage dans `producer/twitter_stream_producer.py`
- Consulter les logs : `docker logs kafka`

### Elasticsearch inaccessible
```bash
curl http://localhost:9200
# Si erreur, restart: docker-compose restart elasticsearch
```

---

## ğŸ“ TODO & AmÃ©liorations

- [ ] Ajouter des tests unitaires
- [ ] ImplÃ©menter le retry logic pour OpenAI
- [ ] CrÃ©er des dashboards Kibana avancÃ©s
- [ ] Ajouter monitoring avec Prometheus
- [ ] Documentation API complÃ¨te

---

## ğŸ‘¨â€ğŸ’» Contributeurs

- **Personne 1** - Kafka Pipeline & Twitter Integration
- **Personne 2** - OpenAI Analysis & Elasticsearch
- **Personne 3** - Cassandra & Kibana Dashboards

---

## Collaboration rules
- Do NOT push to main
- Work only on your branch
- Use Pull Requests for merging

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif dans le cadre du cours de Big Data.

---

## ğŸ†˜ Support

Pour toute question :
- Ouvrir une issue sur GitHub
- Contacter l'Ã©quipe par email
- Consulter la documentation dans `/docs`
