# ğŸ¦ Twitter Real-Time Analysis Pipeline

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Kafka](https://img.shields.io/badge/Kafka-3.6-red.svg)](https://kafka.apache.org)
[![Docker](https://img.shields.io/badge/Docker-required-blue.svg)](https://docker.com)

SystÃ¨me d'analyse de tweets en temps rÃ©el utilisant Kafka, OpenAI, Elasticsearch, Cassandra et Kibana.

## âš ï¸ NOTE IMPORTANTE : Simulateur Local (Pas d'API Twitter)

**Ce projet utilise un SIMULATEUR LOCAL de tweets**, pas l'API Twitter rÃ©elle.

- âœ… **Aucun compte Twitter Developer nÃ©cessaire**
- âœ… **Aucun Bearer Token requis**
- âœ… **Fonctionne 100% localement**
- âœ… **Gratuit et illimitÃ©**

Le simulateur gÃ©nÃ¨re des tweets synthÃ©tiques rÃ©alistes pour tester le pipeline.

---

## ğŸ¯ Objectifs du projet

Analyser des tweets en temps rÃ©el pour extraire :
- âœ… Les hashtags les plus utilisÃ©s
- âœ… Les statistiques des sentiments (positif/nÃ©gatif/neutre)
- âœ… Les mots les plus frÃ©quents
- âœ… Les meilleurs et pires tweets
- âœ… Visualisations interactives avec Kibana

---

## ğŸ—ï¸ Architecture

```
[Simulateur Local]  â† GÃ©nÃ¨re des tweets synthÃ©tiques
    â†“
[Kafka Producer] â†’ [Topic: tweets_raw]
    â†“
[Kafka Consumer]
    â†“
[OpenAI API] (analyse sentiment + topics)
    â†“
[Elasticsearch] (indexation + recherche)
    â†“
[Cassandra] (stockage permanent)
    â†“
[Kibana] (visualisation + dashboards)
```

**SchÃ©ma dÃ©taillÃ© :** Voir [docs/04-architecture.md](docs/04-architecture.md)
**SchÃ©ma dÃ©taillÃ© :** Voir [docs/04-architecture.md](docs/architecture.md)

---

## ğŸ‘¥ Ã‰quipe & ResponsabilitÃ©s

| Membre | OS | Composants | Dossiers |
|--------|----|-----------|-----------------------|
| **Personne 1** | Linux | Kafka + Simulateur | `producer/`, `consumer/`, `data/` |
| **Personne 2** | Linux | OpenAI + Elasticsearch | `analysis/` |
| **Personne 3** | Windows | Cassandra + Kibana | `storage/`, `dashboards/` |

---

## ğŸš€ Installation & Setup

### PrÃ©requis

- **Python 3.8+**
- **Docker & Docker Compose**
- **ClÃ© API OpenAI** (pour Personne 2 uniquement)

**âš ï¸ Aucun compte Twitter Developer nÃ©cessaire** - Ce projet utilise un simulateur local.

### Setup rapide

```bash
# 1. Cloner le repo
git clone https://github.com/votre-username/Twitter-Project.git
cd Twitter-Project

# 2. CrÃ©er l'environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement (uniquement Kafka)
# Le fichier .env existe dÃ©jÃ  avec la config Kafka
cat .env  # VÃ©rifier la configuration

# 5. Lancer Docker (Kafka, Elasticsearch, Kibana, Cassandra)
docker-compose up -d

# 6. Attendre 90 secondes que Kafka dÃ©marre
sleep 90

# 7. VÃ©rifier que tous les services sont UP
docker-compose ps
```

---

## ğŸ® Utilisation

### Terminal 1 : Lancer le Producer (Simulateur)

```bash
source venv/bin/activate
cd producer/
python twitter_simulator.py  # â† Simulateur local (pas d'API Twitter)
```

**Vous verrez :**
```
ğŸ¤– TWITTER SIMULATOR â†’ KAFKA PRODUCER
================================================================================
ğŸ“¤ Kafka: localhost:9092
ğŸ“® Topic: tweets_raw
ğŸ’¡ Simulation de tweets rÃ©alistes en temps rÃ©el
================================================================================

âœ… Tweet #1
   ğŸ‘¤ User: @python_dev
   ğŸ“ Text: Just finished a machine learning project! #Python #AI
   #ï¸âƒ£  Hashtags: #Python, #AI
   ğŸ”„ RT: 42 | â¤ï¸  Likes: 156
```

---

### Terminal 2 : Lancer le Consumer

```bash
source venv/bin/activate
cd consumer/
python consumer.py
```

**Vous verrez les tweets arriver en temps rÃ©el !**

---

### Terminal 3 : Analyse OpenAI (Personne 2)

```bash
source venv/bin/activate
cd analysis/
python analyzer.py
```

---

## ğŸ“Š AccÃ¨s aux interfaces

| Service | URL | Description |
|---------|-----|-------------|
| **Kibana** | http://localhost:5601 | Dashboards & visualisations |
| **Elasticsearch** | http://localhost:9200 | API REST pour requÃªtes |
| **Kafka** | localhost:9092 | Broker Kafka |
| **Cassandra** | localhost:9042 | Base de donnÃ©es NoSQL |

---

## ğŸ“ Structure du projet

```
Twitter-Project/
â”œâ”€â”€ producer/          # Simulateur de tweets â†’ Kafka
â”‚   â”œâ”€â”€ twitter_simulator.py      # â† SIMULATEUR (pas d'API Twitter)
â”‚   â”œâ”€â”€ test_simple_producer.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ consumer/          # Kafka â†’ Processing
â”‚   â”œâ”€â”€ consumer.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ analysis/          # OpenAI + Elasticsearch (Personne 2)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ storage/           # Cassandra setup (Personne 3)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ dashboards/        # Kibana dashboards (Personne 3)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ data/              # Datasets & samples
â”œâ”€â”€ docs/              # Documentation technique
â”‚   â”œâ”€â”€ 01-setup-guide.md
â”‚   â”œâ”€â”€ 02-demo.md
â”‚   â”œâ”€â”€ 03-troubleshooting.md
â”‚   â”œâ”€â”€ 04-architecture.md
â”‚   â”œâ”€â”€ 05-handoff-to-person2.md
â”‚   â””â”€â”€ schema.json
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env               # Configuration (Kafka uniquement)
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Variables d'environnement (.env)

**Le fichier `.env` contient UNIQUEMENT la configuration Kafka :**

```bash
# ==================================
# KAFKA CONFIGURATION
# ==================================
KAFKA_BROKER=localhost:9092
KAFKA_TOPIC=tweets_raw

# ==================================
# NOTE IMPORTANTE
# ==================================
# Ce projet utilise un SIMULATEUR local
# Aucune clÃ© Twitter API n'est nÃ©cessaire
# Le simulateur gÃ©nÃ¨re des tweets synthÃ©tiques
# ==================================
```

**Pour Personne 2** : Ajouter votre clÃ© OpenAI dans `.env` :
```bash
OPENAI_API_KEY=sk-...
```

**âš ï¸ Ne jamais commit le fichier `.env` !**

---

## ğŸ“š Documentation complÃ¨te

| Document | Description |
|----------|-------------|
| [01-setup-guide.md](docs/01-setup-guide.md) | Installation pas Ã  pas |
| [02-demo.md](docs/02-demo.md) | Guide de prÃ©sentation |
| [03-troubleshooting.md](docs/03-troubleshooting.md) | RÃ©solution de problÃ¨mes |
| [04-architecture.md](docs/04-architecture.md) | Architecture du systÃ¨me |
| [05-handoff-to-person2.md](docs/05-handoff-to-person2.md) | Guide pour Personne 2 |
| [schema.json](docs/schema.json) | Format JSON des tweets |

---

## âœ… Ã‰tat d'avancement

### âœ… Personne 1 - Pipeline Kafka (TERMINÃ‰)

#### Infrastructure
- [x] Docker Compose configurÃ© (Kafka, Zookeeper, ES, Kibana, Cassandra)
- [x] Kafka opÃ©rationnel sur localhost:9092
- [x] Topic `tweets_raw` crÃ©Ã© automatiquement
- [x] Configuration rÃ©seau corrigÃ©e

#### Code
- [x] Simulateur de tweets (`producer/twitter_simulator.py`)
- [x] Consumer Kafka (`consumer/consumer.py`)
- [x] Tests de validation
- [x] Scripts de dÃ©marrage

#### Documentation
- [x] 5 guides complets dans `/docs`
- [x] SchÃ©ma JSON standardisÃ©
- [x] README dans chaque dossier

#### Pipeline
```
âœ… Simulateur â†’ Kafka (tweets_raw) â†’ Consumer
     (1-3s)       (<100ms)            (real-time)
```

**DÃ©bit** : 20-60 tweets/minute  
**Latence** : < 100ms

---

### â³ Personne 2 - Analyse (EN COURS)

#### Ã€ faire
- [ ] Lire la documentation : `docs/05-handoff-to-person2.md`
- [ ] Se connecter Ã  Kafka topic `tweets_raw`
- [ ] Analyser avec OpenAI (sentiment, topic, confidence)
- [ ] Indexer dans Elasticsearch
- [ ] CrÃ©er le mapping Elasticsearch

#### Format des donnÃ©es

**EntrÃ©e** (depuis Kafka) :
```json
{
  "tweet_id": "1000000",
  "text": "Just finished a ML project! #Python #AI",
  "user": "python_dev",
  "lang": "en",
  "hashtags": ["Python", "AI"],
  "retweet_count": 42,
  "like_count": 156
}
```

**Sortie** (vers Elasticsearch) :
```json
{
  ..., // DonnÃ©es ci-dessus
  "sentiment": "positive",      // â† Ã€ ajouter
  "topic": "Machine Learning",  // â† Ã€ ajouter
  "confidence": 0.95            // â† Ã€ ajouter
}
```

---

### â³ Personne 3 - Visualisation (EN ATTENTE)

- [ ] Attendre que Personne 2 indexe dans Elasticsearch
- [ ] CrÃ©er les dashboards Kibana
- [ ] Configurer Cassandra (optionnel)

---

## ğŸ¬ DÃ©monstration rapide

### Lancer le pipeline complet

**Terminal 1 - Consumer :**
```bash
source venv/bin/activate
cd consumer && python consumer.py
```

**Terminal 2 - Producer (Simulateur) :**
```bash
source venv/bin/activate
cd producer && python twitter_simulator.py
```

**RÃ©sultat :** Les tweets gÃ©nÃ©rÃ©s par le simulateur apparaissent instantanÃ©ment dans le consumer ! ğŸ‰

---

## ğŸ§ª Tests

### Test 1 : VÃ©rifier que Docker tourne
```bash
docker-compose ps
# Tous les services doivent Ãªtre "Up"
```

### Test 2 : VÃ©rifier que Kafka est prÃªt
```bash
docker logs kafka | grep "started"
# Doit afficher : [KafkaServer id=1] started
```

### Test 3 : Tester le simulateur
```bash
cd producer
python test_simple_producer.py
# Doit envoyer 3 messages de test avec succÃ¨s
```

### Test 4 : VÃ©rifier le topic Kafka
```bash
docker exec -it kafka \
  kafka-topics --list --bootstrap-server localhost:9092
# Doit afficher : tweets_raw
```

---

## ğŸ› DÃ©pannage

### Kafka ne dÃ©marre pas

```bash
docker-compose down -v
docker-compose up -d
sleep 90
docker logs kafka | grep "started"
```

### Le simulateur ne se connecte pas

**Erreur :** `NoBrokersAvailable`

**Solution :**
1. VÃ©rifier que Docker tourne : `docker-compose ps`
2. Attendre 90 secondes aprÃ¨s `docker-compose up -d`
3. VÃ©rifier Kafka : `docker logs kafka | grep started`

### Pas de tweets dans le consumer

**VÃ©rifier :**
1. Le simulateur est lancÃ© : `python twitter_simulator.py`
2. Le topic existe : `docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092`

**Plus de dÃ©tails :** Voir [docs/03-troubleshooting.md](docs/03-troubleshooting.md)

---

## ğŸ¤ Pour Personne 2 (OpenAI + Elasticsearch)

### âœ… Ce qui est prÃªt pour toi

- Kafka opÃ©rationnel sur `localhost:9092`
- Topic `tweets_raw` avec ~20-60 tweets/minute
- Format JSON standardisÃ© (voir `docs/schema.json`)
- Docker Compose avec Elasticsearch sur `localhost:9200`

### ğŸ“š Documentation Ã  lire

1. **Guide principal** : [docs/05-handoff-to-person2.md](docs/05-handoff-to-person2.md)
2. **Format des tweets** : [docs/schema.json](docs/schema.json)
3. **Architecture** : [docs/04-architecture.md](docs/04-architecture.md)

### ğŸš€ Pour dÃ©marrer

```bash
# 1. Pull le repo
git pull origin kafka

# 2. Lancer le simulateur
cd producer
python twitter_simulator.py  # â† GÃ©nÃ¨re des tweets

# 3. Dans ton code, te connecter Ã  Kafka
from kafka import KafkaConsumer
consumer = KafkaConsumer(
    'tweets_raw',
    bootstrap_servers='localhost:9092',
    group_id='analyzer-group'
)
```

### ğŸ“Š Ce que tu dois faire

1. Lire les tweets depuis Kafka (`tweets_raw`)
2. Analyser avec OpenAI â†’ sentiment, topic, confidence
3. Indexer dans Elasticsearch (`tweets_analyzed`)
4. PrÃ©parer le mapping pour Kibana

---

## ğŸ’¡ Pourquoi un simulateur au lieu de l'API Twitter ?

L'API Twitter gratuite a des limitations strictes depuis 2023 :
- âŒ Pas de streaming en temps rÃ©el (Filtered Stream)
- âŒ LimitÃ© Ã  1,500 tweets/mois
- âŒ NÃ©cessite un plan payant ($100+/mois)

**Notre simulateur** :
- âœ… GÃ©nÃ¨re des tweets rÃ©alistes avec hashtags, mÃ©triques
- âœ… Fonctionne 100% localement
- âœ… Gratuit et illimitÃ©
- âœ… Parfait pour tester le pipeline

**Pour passer Ã  la vraie API :** Il suffirait de remplacer `twitter_simulator.py` par un vrai connecteur Tweepy (avec un compte payant).

---

## ğŸ“ TODO & AmÃ©liorations

- [ ] Ajouter des tests unitaires complets
- [ ] ImplÃ©menter le retry logic pour OpenAI
- [ ] CrÃ©er des dashboards Kibana avancÃ©s
- [ ] Ajouter monitoring avec Prometheus
- [ ] Documentation API complÃ¨te

---

## ğŸ‘¨â€ğŸ’» Contributeurs

- **Personne 1** - Pipeline Kafka & Simulateur de tweets
- **Personne 2** - Analyse OpenAI & Indexation Elasticsearch
- **Personne 3** - Visualisation Kibana & Stockage Cassandra

---

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif dans le cadre du cours de Big Data.

---

## ğŸ†˜ Support

Pour toute question :
- Consulter la documentation dans `/docs`
- Ouvrir une issue sur GitHub
- Contacter l'Ã©quipe

---

## ğŸ”— Liens utiles

- [Documentation Kafka](https://kafka.apache.org/documentation/)
- [kafka-python](https://kafka-python.readthedocs.io/)
- [Elasticsearch Guide](https://www.elastic.co/guide/)
- [Docker Compose](https://docs.docker.com/compose/)