# Guide de Passation - Personne 1 â†’ Personne 2

## ğŸ¯ Ce qui est prÃªt pour toi

### âœ… Infrastructure Kafka
- Docker Compose avec tous les services
- Kafka opÃ©rationnel sur `localhost:9092`
- Topic `tweets_raw` crÃ©Ã© automatiquement
- Elasticsearch disponible sur `localhost:9200`

### âœ… Code fonctionnel
- **Simulateur de tweets** : GÃ©nÃ¨re des tweets rÃ©alistes
- **Consumer Kafka** : Lit les tweets du topic
- Format JSON standardisÃ© (voir `docs/schema.json`)

---

## âš ï¸ IMPORTANT : Quel fichier utiliser ?

### âŒ NE PAS UTILISER : `twitter_stream_producer.py`

Ce fichier utilise l'**API Twitter rÃ©elle** (Tweepy) qui nÃ©cessite :
- Un Bearer Token valide (compte Twitter Developer)
- Plan payant ($100+/mois)
- Configuration complexe

**Ce fichier ne fonctionnera PAS pour toi !**

---

### âœ… UTILISER : `twitter_simulator.py`

Ce fichier est un **simulateur local** qui :
- âœ… Fonctionne sans API Twitter
- âœ… GÃ©nÃ¨re des tweets rÃ©alistes
- âœ… Envoie vers Kafka automatiquement
- âœ… Gratuit et illimitÃ©

**C'est CE fichier que tu dois utiliser !**

---

## ğŸš€ DÃ©marrage rapide (30 secondes)

### Ã‰tape 1 : Clone le repo

```bash
cd ~/Documents
git clone <URL_DU_REPO>
cd Twitter-Project
```

### Ã‰tape 2 : DÃ©marre Docker

```bash
docker-compose up -d
sleep 90  # Attendre que Kafka dÃ©marre
```

### Ã‰tape 3 : VÃ©rifie que tout tourne

```bash
docker-compose ps
# Tous les services doivent Ãªtre "Up"
```

### Ã‰tape 4 : Installe Python venv

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ¬ Lancer le pipeline COMPLET

### Terminal 1 : Producer (SIMULATEUR)

```bash
cd ~/Documents/Twitter-Project
source venv/bin/activate
cd producer
python twitter_simulator.py  # â† CE FICHIER !
```

**Tu verras :**
```
================================================================================
ğŸ¤– TWITTER SIMULATOR â†’ KAFKA PRODUCER
================================================================================
ğŸ“¤ Kafka: localhost:9092
ğŸ“® Topic: tweets_raw
================================================================================

âœ… Tweet #1
   ğŸ‘¤ User: @python_dev
   ğŸ“ Text: Just finished a ML project! #Python #AI
   #ï¸âƒ£  Hashtags: #Python, #AI
   ğŸ”„ RT: 42 | â¤ï¸  Likes: 156
--------------------------------------------------------------------------------
```

### Terminal 2 : Ton Analyzer

```bash
cd ~/Documents/Twitter-Project
source venv/bin/activate
cd analysis
python analyzer.py  # Ton code d'analyse
```

**Il devrait recevoir les tweets et les analyser ! ğŸ‰**

---

## ğŸ“Š Format des tweets reÃ§us

Chaque tweet dans Kafka a ce format (voir `docs/schema.json`) :

```json
{
  "tweet_id": "1000000",
  "text": "Just finished a machine learning project! #Python #AI",
  "created_at": "2026-01-26T23:30:00.000Z",
  "user": "python_dev",
  "lang": "en",
  "hashtags": ["Python", "AI"],
  "retweet_count": 42,
  "like_count": 156
}
```

**Tu dois ajouter :**
```json
{
  ...,
  "sentiment": "positive",      // â† OpenAI
  "topic": "Machine Learning",  // â† OpenAI
  "confidence": 0.95            // â† OpenAI
}
```

---

## ğŸ§ª Tester que Kafka reÃ§oit des tweets

### Option 1 : Consumer test (Python)

```bash
source venv/bin/activate
cd consumer
python consumer.py
```

**Si tu vois des tweets s'afficher â†’ Kafka fonctionne ! âœ…**

### Option 2 : Console Kafka

```bash
docker exec -it kafka \
  kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic tweets_raw \
  --from-beginning
```

**Tu dois voir des messages JSON.**

---

## ğŸ”§ Connexion Ã  Kafka depuis ton code

### Consumer Python basique

```python
from kafka import KafkaConsumer
import json

# Configuration
consumer = KafkaConsumer(
    'tweets_raw',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest',
    group_id='analyzer-group'  # Ton group ID
)

print("ğŸ“¥ En attente des tweets...")

# Lire les tweets
for message in consumer:
    tweet = message.value
    
    # Ton code d'analyse ici
    print(f"Tweet reÃ§u : {tweet['text']}")
    
    # 1. Analyser avec OpenAI
    sentiment = analyze_with_openai(tweet['text'])
    
    # 2. Enrichir le tweet
    tweet['sentiment'] = sentiment
    
    # 3. Indexer dans Elasticsearch
    index_to_elasticsearch(tweet)
```

---

## ğŸ› ProblÃ¨mes courants

### ProblÃ¨me 1 : "No module named 'kafka'"

**Cause** : venv pas activÃ©

**Solution** :
```bash
source venv/bin/activate
```

### ProblÃ¨me 2 : "NoBrokersAvailable"

**Cause** : Kafka pas encore prÃªt

**Solution** :
```bash
# Attendre 90 secondes aprÃ¨s docker-compose up
sleep 90

# VÃ©rifier
docker logs kafka | grep "started"
```

### ProblÃ¨me 3 : "Aucun tweet reÃ§u"

**Cause** : Le simulateur n'est pas lancÃ©

**Solution** :
```bash
# Terminal sÃ©parÃ©
cd producer
python twitter_simulator.py  # â† Pas twitter_stream_producer.py !
```

### ProblÃ¨me 4 : Topic vide

**VÃ©rifier** :
```bash
# Lister les topics
docker exec -it kafka \
  kafka-topics --list --bootstrap-server localhost:9092

# Si tweets_raw absent, crÃ©er
docker exec -it kafka \
  kafka-topics --create --topic tweets_raw \
  --bootstrap-server localhost:9092 \
  --partitions 1 --replication-factor 1
```

---

## ğŸ“‹ Checklist de dÃ©marrage

```
â˜ Repo clonÃ©
â˜ docker-compose up -d lancÃ©
â˜ Attendu 90 secondes
â˜ docker-compose ps â†’ tous "Up"
â˜ venv crÃ©Ã© et activÃ©
â˜ requirements.txt installÃ©
â˜ Terminal 1 : python twitter_simulator.py (simulateur)
â˜ Terminal 2 : ton analyzer.py
â˜ Les tweets arrivent dans ton analyzer
```

---

## ğŸ¯ Ce que tu dois faire

1. **Recevoir les tweets** depuis Kafka (`tweets_raw`)
2. **Analyser chaque tweet** avec OpenAI :
   - Sentiment (positive/negative/neutral)
   - Topic principal
   - Score de confiance
3. **Indexer dans Elasticsearch** :
   - Index : `tweets_analyzed`
   - Mapping avec les nouveaux champs
4. **PrÃ©parer pour Personne 3** :
   - Kibana doit voir l'index `tweets_analyzed`

---

## ğŸ“ Besoin d'aide ?

**ProblÃ¨mes avec le simulateur ?**
- VÃ©rifie que Docker tourne : `docker-compose ps`
- VÃ©rifie les logs Kafka : `docker logs kafka`
- Lis le troubleshooting : `docs/03-troubleshooting.md`

**ProblÃ¨mes avec ton analyzer ?**
- Teste d'abord avec `consumer/consumer.py`
- VÃ©rifie Elasticsearch : `curl http://localhost:9200`

---

## ğŸ”— Ressources

- **Setup complet** : [docs/01-setup-guide.md](01-setup-guide.md)
- **Format JSON** : [docs/schema.json](schema.json)
- **Architecture** : [docs/04-architecture.md](04-architecture.md)
- **Troubleshooting** : [docs/03-troubleshooting.md](03-troubleshooting.md)

---

## âœ… RÃ©sumÃ©

| Fichier | Ã€ utiliser ? | Pourquoi |
|---------|--------------|----------|
| `twitter_simulator.py` | âœ… OUI | Fonctionne sans API Twitter |
| `twitter_stream_producer.py` | âŒ NON | NÃ©cessite API Twitter payante |

**Utilise le SIMULATEUR et tout fonctionnera ! ğŸš€**