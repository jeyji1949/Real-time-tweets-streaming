# Architecture du SystÃ¨me - Twitter Real-Time Analysis

## ğŸ—ï¸ Vue d'ensemble

Pipeline de streaming temps rÃ©el pour l'analyse de tweets utilisant Apache Kafka comme systÃ¨me de messagerie central.

---

## ğŸ“Š Diagramme d'architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TWITTER ANALYSIS PIPELINE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   PERSONNE 1 â”‚
                           â”‚    (Kafka)   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
        â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Simulator   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Consumer   â”‚
â”‚  (Producer)   â”‚  JSON   â”‚  tweets_raw  â”‚  JSON   â”‚   (Reader)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
                          â”‚   PERSONNE 2 â”‚                â”‚
                          â”‚ (OpenAI + ES)â”‚                â”‚
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                                 â”‚                        â”‚
                                 â–¼                        â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  OpenAI API  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Analysis   â”‚
                          â”‚  (Sentiment  â”‚         â”‚   Module    â”‚
                          â”‚   + Topics)  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚Elasticsearch â”‚
                          â”‚   (Index)    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                â”‚                â”‚
                â–¼                â–¼                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  PERSONNE 3   â”‚          â”‚    â”‚          â”‚
         â”‚  (Viz/Store)  â”‚          â”‚    â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â”‚          â”‚    â”‚          â”‚
                â”‚        â”‚          â”‚    â”‚          â”‚
                â–¼        â–¼          â–¼    â–¼          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Kibana  â”‚ â”‚Cassandra â”‚ â”‚ Storage  â”‚
         â”‚(Dashboards)â”‚(Permanent)â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flux de donnÃ©es dÃ©taillÃ©

### Ã‰tape 1 : GÃ©nÃ©ration (Personne 1)

**Composant** : `producer/twitter_simulator.py`

**Fonction** :
- GÃ©nÃ¨re des tweets rÃ©alistes toutes les 1-3 secondes
- Simule des donnÃ©es Twitter authentiques

**DonnÃ©es gÃ©nÃ©rÃ©es** :
```json
{
  "tweet_id": "1000000",
  "text": "Just finished a ML project! #Python #AI",
  "created_at": "2026-01-26T23:30:00",
  "user": "python_dev",
  "lang": "en",
  "hashtags": ["Python", "AI"],
  "retweet_count": 42,
  "like_count": 156
}
```

---

### Ã‰tape 2 : Production vers Kafka (Personne 1)

**Composant** : Kafka Producer dans le simulateur

**Configuration** :
```python
producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)
```

**Action** :
```python
producer.send('tweets_raw', value=tweet_data)
```

**Topic Kafka** : `tweets_raw`
- 1 partition
- Replication factor: 1
- Retention: 7 jours (168 heures)

---

### Ã‰tape 3 : Stockage dans Kafka

**Broker Kafka** :
- Persiste les messages sur disque
- Garantit la durabilitÃ© des donnÃ©es
- Permet le replay des messages

**Avantages** :
- âœ… Buffer entre producer et consumer
- âœ… Plusieurs consumers possibles
- âœ… RÃ©silience aux pannes
- âœ… ScalabilitÃ© horizontale

---

### Ã‰tape 4 : Consommation (Personne 1)

**Composant** : `consumer/consumer.py`

**Configuration** :
```python
consumer = KafkaConsumer(
    'tweets_raw',
    bootstrap_servers='localhost:9092',
    group_id='tweet-consumer-group',
    auto_offset_reset='earliest'
)
```

**Fonction** :
- Lit les tweets depuis Kafka
- Affiche en temps rÃ©el
- Transmet Ã  l'Ã©tape suivante

---

### Ã‰tape 5 : Analyse (Personne 2) â³

**Composants** :
- Module d'analyse OpenAI
- Indexation Elasticsearch

**Fonctions prÃ©vues** :
1. Analyser le sentiment (positif/nÃ©gatif/neutre)
2. Extraire les topics principaux
3. Indexer dans Elasticsearch

**Format enrichi** :
```json
{
  "tweet_id": "1000000",
  "text": "Just finished a ML project!",
  "sentiment": "positive",      // â† AjoutÃ© par OpenAI
  "topic": "Machine Learning",  // â† AjoutÃ© par OpenAI
  "confidence": 0.95,
  ...
}
```

---

### Ã‰tape 6 : Visualisation (Personne 3) â³

**Composants** :
- Kibana pour dashboards
- Cassandra pour stockage permanent

**Dashboards prÃ©vus** :
- Distribution des sentiments
- Top hashtags
- Timeline des tweets
- Carte des mots-clÃ©s

---

## ğŸ³ Infrastructure Docker

### Services dÃ©ployÃ©s

| Service | Image | Port | Fonction |
|---------|-------|------|----------|
| Zookeeper | `confluentinc/cp-zookeeper:7.4.0` | 2181 | Coordination Kafka |
| Kafka | `confluentinc/cp-kafka:7.4.0` | 9092 | Message broker |
| Elasticsearch | `elastic/elasticsearch:8.11.0` | 9200 | Indexation |
| Kibana | `elastic/kibana:8.11.0` | 5601 | Visualisation |
| Cassandra | `cassandra:4.1` | 9042 | Base NoSQL |

### Configuration rÃ©seau

**Kafka Listeners** :
```yaml
KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
```

**Explication** :
- `kafka:29092` : Communication interne Docker
- `localhost:9092` : Communication depuis la machine hÃ´te

---

## ğŸ”§ Technologies utilisÃ©es

### Backend

| Tech | Version | Usage |
|------|---------|-------|
| Python | 3.12 | Langage principal |
| kafka-python | 2.0.2 | Client Kafka |
| Docker | 20.10+ | Conteneurisation |
| Docker Compose | 2.0+ | Orchestration |

### Kafka Ecosystem

| Composant | RÃ´le |
|-----------|------|
| Zookeeper | Gestion de la configuration Kafka |
| Broker | Stockage et distribution des messages |
| Topics | Canaux de communication |
| Partitions | ParallÃ©lisation du traitement |

### Data Stack (Ã  venir)

| Tech | Version | Usage (Personne 2/3) |
|------|---------|----------------------|
| OpenAI API | GPT-4 | Analyse NLP |
| Elasticsearch | 8.11.0 | Indexation fulltext |
| Kibana | 8.11.0 | Dashboards |
| Cassandra | 4.1 | Stockage NoSQL |

---

## ğŸ“Š MÃ©triques et performances

### CapacitÃ©s actuelles

- **Throughput** : ~1 tweet/1-3 secondes (configurable)
- **Latence** : < 100ms entre producer et consumer
- **DurabilitÃ©** : Messages persistÃ©s 7 jours
- **ScalabilitÃ©** : 1 partition (extensible Ã  N partitions)

### Limites actuelles

- 1 broker Kafka (pas de haute disponibilitÃ©)
- 1 partition (pas de parallÃ©lisation)
- Pas de rÃ©plication (factor = 1)

### AmÃ©liorations possibles

Pour production :
- 3+ brokers Kafka (haute disponibilitÃ©)
- RÃ©plication factor = 3
- Multiples partitions (parallÃ©lisation)
- Monitoring (Prometheus + Grafana)

---

## ğŸ” SÃ©curitÃ©

### Actuel (DÃ©veloppement)

- âŒ Pas d'authentification Kafka
- âŒ Pas de chiffrement
- âŒ Pas de contrÃ´le d'accÃ¨s

**âš ï¸ Configuration de dÃ©veloppement uniquement !**

### Pour Production

Ajouter :
- âœ… SASL authentication
- âœ… SSL/TLS encryption
- âœ… ACL (Access Control Lists)
- âœ… Secrets management (Vault)

---

## ğŸ”„ Ã‰tats du systÃ¨me

### Ã‰tat 1 : DÃ©marrage

```
Docker Compose up â†’ Zookeeper dÃ©marre (5s)
                  â†’ Kafka dÃ©marre (30s)
                  â†’ ES/Kibana/Cassandra dÃ©marrent (30s)
                  â†’ Topic auto-crÃ©Ã© au 1er message
```

### Ã‰tat 2 : Fonctionnement normal

```
Simulator â†’ Kafka â†’ Consumer
  (1-3s)     (<100ms)   (temps rÃ©el)
```

### Ã‰tat 3 : ArrÃªt

```
Ctrl+C â†’ Producer s'arrÃªte
       â†’ Consumer s'arrÃªte
       â†’ Messages restent dans Kafka (7 jours)
```

---

## ğŸ“ Structure du projet

```
Twitter-Project/
â”œâ”€â”€ docker-compose.yml      # Infrastructure
â”œâ”€â”€ .env                    # Configuration
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚
â”œâ”€â”€ producer/               # Personne 1
â”‚   â”œâ”€â”€ twitter_simulator.py
â”‚   â”œâ”€â”€ test_simple_producer.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ consumer/               # Personne 1
â”‚   â”œâ”€â”€ consumer.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ analysis/               # Personne 2 (Ã  faire)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ storage/                # Personne 3 (Ã  faire)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ dashboards/             # Personne 3 (Ã  faire)
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ docs/                   # Documentation
    â”œâ”€â”€ 01-setup-guide.md
    â”œâ”€â”€ 02-demo.md
    â”œâ”€â”€ 03-troubleshooting.md
    â”œâ”€â”€ 04-architecture.md
    â””â”€â”€ schema.json
```

---

## ğŸ¯ Ã‰tat d'avancement

### âœ… ComplÃ©tÃ© (Personne 1)

- [x] Infrastructure Docker
- [x] Topic Kafka `tweets_raw`
- [x] Simulateur de tweets
- [x] Producer Kafka
- [x] Consumer Kafka
- [x] Tests et validation
- [x] Documentation

### â³ En attente (Personne 2)

- [ ] IntÃ©gration OpenAI
- [ ] Analyse des sentiments
- [ ] Extraction de topics
- [ ] Indexation Elasticsearch

### â³ En attente (Personne 3)

- [ ] Dashboards Kibana
- [ ] Stockage Cassandra
- [ ] Visualisations finales

---

## ğŸ”— Interfaces de communication

### Entre Personne 1 et Personne 2

**Topic Kafka** : `tweets_raw`  
**Format** : JSON (voir `schema.json`)  
**FrÃ©quence** : ~1 tweet/1-3 secondes

### Entre Personne 2 et Personne 3

**Elasticsearch** : `http://localhost:9200`  
**Index** : `tweets_analyzed`  
**Format** : JSON enrichi avec sentiment et topic

---

## ğŸ“š RÃ©fÃ©rences

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [kafka-python](https://kafka-python.readthedocs.io/)
- [Docker Compose](https://docs.docker.com/compose/)
- [Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)

---

**Architecture mise Ã  jour** : 26 janvier 2026  
**Version** : 1.0  
**Auteur** : EL KHRAIBI Jihane (Pipeline Kafka)
