# Real-time Tweets Streaming

Ce projet met en place un pipeline de traitement en temps r√©el de tweets avec Kafka, Elasticsearch, Kibana et un service `analyzer_improved.py` pour analyser et indexer les tweets.

## Guide pratique pour suivre et tester le pipeline

### 1Ô∏è‚É£ Consulter les logs en temps r√©el

Pour voir ce que fait le service `analyzer_improved` :

```bash
docker logs -f analyzer_improved
```

- `-f` = ‚Äúfollow‚Äù ‚Üí affiche les nouveaux logs en temps r√©el.
- Tu verras quand un tweet est trait√©, index√© dans Elasticsearch ou envoy√© dans le DLQ.

---

### 2Ô∏è‚É£ V√©rifier les topics Kafka

#### a) Consommer le topic principal (`tweets_raw`)

```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:29092 \
  --topic tweets_raw \
  --from-beginning
```

- Affiche les tweets bruts qui arrivent dans Kafka.
- Supprime `--from-beginning` pour ne voir que les nouveaux messages.

#### b) Consommer le DLQ (`tweets_failed`)

```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:29092 \
  --topic tweets_failed \
  --from-beginning
```

- Montre les tweets qui n‚Äôont pas pu √™tre index√©s (ex. probl√®me de connexion Elasticsearch).

---

### 3Ô∏è‚É£ Tester l‚Äôindexation dans Elasticsearch

Voir tous les indices existants :

```bash
curl -X GET "http://localhost:9200/_cat/indices?v"
```

Afficher les 5 derniers documents :

```bash
curl -X GET "http://localhost:9200/tweets/_search?size=5&sort=indexed_at:desc"
```

- Change `size=5` pour plus de documents.

---

### 4Ô∏è‚É£ Consulter via Kibana

- Ouvre ton navigateur : [http://localhost:5601](http://localhost:5601)
- Cr√©e un **Index Pattern** sur ton index `tweets`
- Explorer les documents, visualiser les statistiques, appliquer des filtres.

---

### 5Ô∏è‚É£ V√©rifier l‚Äô√©tat des services Docker

```bash
docker compose ps
```

- Permet de voir si **Kafka, Elasticsearch, Kibana, analyzer_improved** sont bien "Up" et healthy.

---

üí° **Astuce** : Si tu ajoutes de nouveaux tweets dans Kafka, ils seront automatiquement trait√©s et index√©s par `analyzer_improved`.

---

### 6Ô∏è‚É£ Exemple de test rapide

Tu peux injecter un tweet de test dans Kafka :

```bash
docker exec -i kafka kafka-console-producer \
  --bootstrap-server kafka:29092 \
  --topic tweets_raw <<EOF
{"tweet_id": "12345", "text": "Test tweet for analyzer_improved", "created_at": "2026-02-21T10:00:00", "user": "test_user", "lang": "en", "hashtags": ["Test"], "retweet_count": 0, "like_count": 0}
EOF
```

- V√©rifie ensuite les logs de `analyzer_improved` et Elasticsearch pour voir si le tweet est bien index√©.
---

## üß± Architecture globale

- **Kafka** : ingestion et transport des tweets
- **Python consumers** : analyse des tweets + gestion des erreurs
- **Elasticsearch** : indexation et recherche
- **Docker & Docker Compose** : orchestration

Topics Kafka :
- `tweets_raw` ‚Üí tweets entrants
- `tweets_failed` ‚Üí tweets √©chou√©s (erreurs d‚Äôanalyse ou d‚Äôindexation)

Index Elasticsearch :
- `tweets_index_improved`

---

## üöÄ Lancer le projet

```bash
docker compose up
```

Pour quitter les logs sans arr√™ter les services :
- Appuyer sur `d` (detach)

---

## üîπ Phase 2 : V√©rification de la consommation & des tweets √©chou√©s

### 1Ô∏è‚É£ V√©rifier que les topics existent

```bash
docker exec -it kafka kafka-topics   --bootstrap-server localhost:29092   --list
```

Tu dois voir :
- `tweets_raw`
- `tweets_failed`

---

### 2Ô∏è‚É£ V√©rifier les tweets √©chou√©s (format lisible)

```bash
docker exec -it kafka kafka-console-consumer   --bootstrap-server localhost:29092   --topic tweets_failed   --from-beginning   --max-messages 10   | jq '{tweet_id: .original_tweet.tweet_id, text: .original_tweet.text, error_type, error_message, failed_at}'
```

√Ä v√©rifier :
- pr√©sence de `tweet_id`
- type d‚Äôerreur (`error_type`)
- message d‚Äôerreur (`error_message`)

---

### 3Ô∏è‚É£ V√©rifier le groupe de consommateurs Kafka

```bash
docker exec -it kafka kafka-consumer-groups   --bootstrap-server localhost:29092   --describe   --group analyzer-group-v2
```

R√©sultat attendu :
- `CURRENT-OFFSET = LOG-END-OFFSET`
- `LAG = 0`

‚û°Ô∏è Cela confirme que **tous les tweets ont √©t√© consomm√©s**.

---

## üîπ Phase 3 : V√©rification de l‚Äôindexation Elasticsearch

### 1Ô∏è‚É£ V√©rifier que l‚Äôindex existe

```bash
curl -X GET "http://localhost:9200/tweets_index_improved?pretty"
```

---

### 2Ô∏è‚É£ V√©rifier le mapping

```bash
curl -X GET "http://localhost:9200/tweets_index_improved/_mapping?pretty"
```

Champs attendus :
- `tweet_id`
- `text`
- `hashtags`
- `sentiment`
- `topic`
- `analysis_method`
- `confidence`
- `created_at`

V√©rifie que les types correspondent au fichier `mapping_improved.json`.

---

### 3Ô∏è‚É£ V√©rifier le nombre total de tweets index√©s

```bash
curl -X GET "http://localhost:9200/tweets_index_improved/_search?pretty&q=*:*&size=0"
```

La valeur :
```json
hits.total.value
```
doit correspondre au nombre de tweets g√©n√©r√©s.

---

### 4Ô∏è‚É£ V√©rifier des tweets pr√©cis par ID

```bash
curl -s -X GET "http://localhost:9200/tweets_index_improved/_search?pretty" -H 'Content-Type: application/json' -d '{
  "query": {
    "terms": {
      "tweet_id": ["1000191", "1000193", "1000220"]
    }
  }
}' | jq ".hits.hits[]._source | {tweet_id, text}"
```

‚û°Ô∏è V√©rifie que :
- les tweets sont bien pr√©sents
- le texte correspond

---

### 5Ô∏è‚É£ V√©rifier la coh√©rence des champs index√©s

```bash
curl -s -X GET "http://localhost:9200/tweets_index_improved/_search?pretty&q=*:*&size=5" | jq ".hits.hits[]._source | {tweet_id, text, sentiment, topic, analysis_method}"
```

‚û°Ô∏è Chaque document doit contenir **tous les champs du mapping**.

---

## üß™ Debug rapide (si √ßa ne marche pas)

- Aucun tweet dans Elasticsearch ?
  - V√©rifier que les consumers Python tournent
  - V√©rifier `tweets_failed`
- Tweets √©chou√©s nombreux ?
  - V√©rifier les logs du consumer
  - V√©rifier les champs envoy√©s √† Elasticsearch

---

## üìå Bonnes pratiques

- Utiliser `jq` pour des sorties lisibles
- V√©rifier r√©guli√®rement `LAG = 0`
- Tester Elasticsearch avec des requ√™tes simples avant des requ√™tes complexes

---

## ‚úÖ Validation du projet

‚úî Les topics Kafka existent  
‚úî Les tweets sont consomm√©s sans lag  
‚úî Les erreurs sont stock√©es dans `tweets_failed`  
‚úî Les tweets sont index√©s dans `tweets_index_improved`  
‚úî Le mapping est respect√©  

---
