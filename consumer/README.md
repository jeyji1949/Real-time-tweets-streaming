# ğŸ“¥ Consumer Kafka - RÃ©ception des Tweets

## ğŸ¯ Description

Le consumer Kafka lit les tweets en temps rÃ©el depuis le topic `tweets_raw` et les affiche dans la console.

**RÃ´le dans le pipeline** :
```
[Simulateur] â†’ [Kafka: tweets_raw] â†’ [Consumer] â†’ [Affichage/Traitement]
                                          â†‘
                                       VOUS ÃŠTES ICI
```

---

## ğŸ“ Fichiers

| Fichier | Description | Usage |
|---------|-------------|-------|
| `consumer.py` | Consumer principal | `python consumer.py` |
| `README.md` | Ce fichier | Documentation |

---

## ğŸš€ Utilisation

### DÃ©marrage du consumer

```bash
# 1. Activer le venv
cd ~/Documents/BIAM/BIGDATA/Twitter-Project
source venv/bin/activate

# 2. Aller dans consumer
cd consumer

# 3. Lancer le consumer
python consumer.py
```

### RÃ©sultat attendu

```
================================================================================
ğŸ“¥ KAFKA CONSUMER - RÃ©ception des tweets
================================================================================
ğŸ“¡ Kafka Broker: localhost:9092
ğŸ“® Topic: tweets_raw
================================================================================

ğŸ”„ Tentative de connexion Ã  Kafka (1/10)...
âœ… Connexion Ã  Kafka rÃ©ussie !

â¸ï¸  Ctrl+C pour arrÃªter
================================================================================

ğŸ‘‚ En Ã©coute des tweets...

ğŸ“© Tweet #1 reÃ§u
   ID: 1000000
   ğŸ‘¤ User: python_dev
   ğŸ“ Text: Just finished a machine learning project! #Python #AI
   ğŸŒ Lang: en
   #ï¸âƒ£  Hashtags: #Python, #AI
   ğŸ”„ Retweets: 42
   â¤ï¸  Likes: 156
--------------------------------------------------------------------------------
ğŸ“© Tweet #2 reÃ§u
   ID: 1000001
   ğŸ‘¤ User: ai_researcher
   ğŸ“ Text: Amazing tutorial on neural networks! #MachineLearning
   ğŸŒ Lang: en
   #ï¸âƒ£  Hashtags: #MachineLearning
   ğŸ”„ Retweets: 67
   â¤ï¸  Likes: 342
--------------------------------------------------------------------------------
```

**Le consumer reste ouvert et affiche chaque tweet au fur et Ã  mesure qu'il arrive.**

---

## ğŸ”§ Comment Ã§a marche ?

### 1. Configuration

```python
KAFKA_BROKER = os.getenv('KAFKA_BROKER', 'localhost:9092')
KAFKA_TOPIC = os.getenv('KAFKA_TOPIC', 'tweets_raw')
```

Le consumer lit la configuration depuis `../.env` :
- **Broker** : Adresse du serveur Kafka
- **Topic** : Nom du topic Ã  lire

---

### 2. CrÃ©ation du consumer

```python
consumer = KafkaConsumer(
    KAFKA_TOPIC,                    # Topic Ã  Ã©couter
    bootstrap_servers=KAFKA_BROKER, # Adresse Kafka
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),  # DÃ©code JSON
    auto_offset_reset='earliest',   # Lire depuis le dÃ©but
    enable_auto_commit=True,        # Sauvegarder la position
    group_id='tweet-consumer-group' # Groupe de consumers
)
```

**Explications** :

| ParamÃ¨tre | Explication |
|-----------|-------------|
| `bootstrap_servers` | OÃ¹ se trouve Kafka (localhost:9092) |
| `value_deserializer` | Convertit les bytes en JSON Python |
| `auto_offset_reset='earliest'` | Si premier lancement, lire depuis le dÃ©but |
| `enable_auto_commit=True` | Kafka sauvegarde automatiquement oÃ¹ on en est |
| `group_id` | Identifiant du groupe de consumers |

---

### 3. Boucle de lecture

```python
for message in consumer:
    tweet = message.value  # Extraire le JSON du message
    
    # Afficher les informations
    print(f"ğŸ“© Tweet #{tweet_count} reÃ§u")
    print(f"   ID: {tweet['tweet_id']}")
    print(f"   ğŸ‘¤ User: {tweet['user']}")
    print(f"   ğŸ“ Text: {tweet['text'][:100]}...")
    # etc.
```

**La boucle tourne indÃ©finiment** jusqu'Ã  `Ctrl+C`.

---

### 4. Retry logic (connexion automatique)

Si Kafka n'est pas encore prÃªt, le consumer essaie 10 fois :

```python
for attempt in range(1, max_retries + 1):
    try:
        consumer = KafkaConsumer(...)
        print("âœ… Connexion rÃ©ussie")
        break
    except NoBrokersAvailable:
        print(f"âš ï¸  Tentative {attempt}/10...")
        time.sleep(3)
```

**Avantage** : Pas besoin de relancer manuellement si Kafka dÃ©marre lentement.

---

## ğŸ“Š Format des donnÃ©es reÃ§ues

Chaque message reÃ§u est un **objet JSON** :

```json
{
  "tweet_id": "1000000",
  "text": "Just finished a machine learning project! #Python #AI",
  "created_at": "2026-01-27T10:30:00.000Z",
  "user": "python_dev",
  "lang": "en",
  "hashtags": ["Python", "AI"],
  "retweet_count": 42,
  "like_count": 156
}
```

**Voir le schÃ©ma complet** : [../docs/schema.json](../docs/schema.json)

---

## ğŸ¯ Ã€ quoi sert le consumer ?

### RÃ´le dans le projet

Le consumer a **3 fonctions principales** :

1. **VÃ©rifier que le pipeline fonctionne**
   - Si les tweets s'affichent â†’ Le producer et Kafka fonctionnent âœ…

2. **DÃ©bugger le flux de donnÃ©es**
   - Voir les tweets bruts avant traitement
   - VÃ©rifier le format JSON

3. **Base pour Personne 2**
   - Ce code montre comment se connecter Ã  Kafka
   - Personne 2 peut s'en inspirer pour son analyzer

---

## ğŸ”§ Configuration avancÃ©e

### Changer le group ID

Si vous voulez plusieurs consumers indÃ©pendants :

```python
consumer = KafkaConsumer(
    KAFKA_TOPIC,
    group_id='mon-consumer-unique'  # â† Changer ici
)
```

**Avec le mÃªme group_id** : Les consumers se partagent les messages (load balancing)  
**Avec des group_id diffÃ©rents** : Chaque consumer reÃ§oit TOUS les messages

---

### Lire depuis le dernier message

```python
consumer = KafkaConsumer(
    KAFKA_TOPIC,
    auto_offset_reset='latest'  # â† Lire seulement les nouveaux
)
```

**'earliest'** : Lire tous les messages depuis le dÃ©but (par dÃ©faut)  
**'latest'** : Lire seulement les nouveaux messages

---

### Ajouter un timeout

```python
consumer = KafkaConsumer(
    KAFKA_TOPIC,
    consumer_timeout_ms=10000  # ArrÃªte aprÃ¨s 10s sans message
)
```

**âš ï¸ Attention** : Avec un timeout, le consumer s'arrÃªte s'il ne reÃ§oit rien !

---

## ğŸ§ª Tests

### Test 1 : VÃ©rifier que Kafka tourne

```bash
docker-compose ps | grep kafka
# Doit afficher : Up
```

### Test 2 : VÃ©rifier que le topic existe

```bash
docker exec -it kafka \
  kafka-topics --list --bootstrap-server localhost:9092
# Doit afficher : tweets_raw
```

### Test 3 : Lire manuellement le topic

```bash
docker exec -it kafka \
  kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic tweets_raw \
  --from-beginning \
  --max-messages 5
```

**Si vous voyez des messages JSON** â†’ Le topic contient des donnÃ©es âœ…

---

## ğŸ› DÃ©pannage

### ProblÃ¨me 1 : "ModuleNotFoundError: No module named 'kafka'"

**Cause** : venv pas activÃ©

**Solution** :
```bash
source ../venv/bin/activate
```

**VÃ©rifier** :
```bash
which python
# Doit contenir "venv"
```

---

### ProblÃ¨me 2 : "NoBrokersAvailable"

**Cause** : Kafka pas encore prÃªt ou pas dÃ©marrÃ©

**Solution** :
```bash
# VÃ©rifier Docker
docker-compose ps

# Si pas UP
docker-compose up -d
sleep 90

# VÃ©rifier Kafka
docker logs kafka | grep "started"
```

---

### ProblÃ¨me 3 : Le consumer se connecte mais ne reÃ§oit rien

**Causes possibles** :

1. **Le producer n'est pas lancÃ©**
   ```bash
   # Terminal 2
   cd producer
   python twitter_simulator.py
   ```

2. **Le topic est vide**
   ```bash
   # VÃ©rifier
   docker exec -it kafka \
     kafka-console-consumer \
     --bootstrap-server localhost:9092 \
     --topic tweets_raw \
     --from-beginning \
     --max-messages 1
   ```

3. **Offset dÃ©jÃ  au bout**
   ```bash
   # RÃ©initialiser le consumer group
   docker exec -it kafka \
     kafka-consumer-groups \
     --bootstrap-server localhost:9092 \
     --group tweet-consumer-group \
     --reset-offsets \
     --to-earliest \
     --topic tweets_raw \
     --execute
   ```

---

### ProblÃ¨me 4 : Le consumer se ferme immÃ©diatement

**Cause** : Un timeout est configurÃ© dans le code

**Solution** : VÃ©rifier qu'il n'y a PAS cette ligne dans `consumer.py` :
```python
consumer_timeout_ms=1000  # â† Ã€ SUPPRIMER
```

---

## ğŸ”„ Workflow typique

### DÃ©marrage du pipeline complet

**Terminal 1 - Consumer :**
```bash
cd ~/Documents/BIAM/BIGDATA/Twitter-Project
source venv/bin/activate
cd consumer
python consumer.py
```

**Terminal 2 - Producer :**
```bash
cd ~/Documents/BIAM/BIGDATA/Twitter-Project
source venv/bin/activate
cd producer
python twitter_simulator.py
```

**RÃ©sultat** : Les tweets du producer apparaissent dans le consumer en temps rÃ©el ! ğŸ‰

---

## ğŸ“š Pour aller plus loin

### Modifier l'affichage

Vous pouvez personnaliser comment les tweets sont affichÃ©s.

**Exemple - Affichage minimal :**
```python
for message in consumer:
    tweet = message.value
    print(f"[{tweet['user']}] {tweet['text']}")
```

**Exemple - Sauvegarder dans un fichier :**
```python
with open('tweets.log', 'a') as f:
    for message in consumer:
        tweet = message.value
        f.write(json.dumps(tweet) + '\n')
        print(f"âœ… Tweet {tweet['tweet_id']} sauvegardÃ©")
```

**Exemple - Filtrer par langue :**
```python
for message in consumer:
    tweet = message.value
    if tweet['lang'] == 'en':  # Seulement anglais
        print(f"ğŸ“© Tweet: {tweet['text']}")
```

---

### CrÃ©er un consumer personnalisÃ©

Pour **Personne 2**, voici un exemple de consumer qui prÃ©pare pour OpenAI :

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'tweets_raw',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    group_id='analyzer-group'  # Groupe diffÃ©rent
)

print("ğŸ“Š Analyzer Consumer - En attente des tweets...")

for message in consumer:
    tweet = message.value
    
    # 1. Analyser avec OpenAI (Ã  implÃ©menter)
    # sentiment = analyze_sentiment(tweet['text'])
    
    # 2. Enrichir le tweet
    # tweet['sentiment'] = sentiment
    
    # 3. Indexer dans Elasticsearch (Ã  implÃ©menter)
    # index_to_elasticsearch(tweet)
    
    print(f"âœ… Tweet {tweet['tweet_id']} traitÃ©")
```

---

## ğŸ“ Concepts Kafka importants

### Offset

**DÃ©finition** : La position du consumer dans le topic (quel message il lit)

**Exemple** :
```
Topic tweets_raw:
  Offset 0: Tweet #1
  Offset 1: Tweet #2
  Offset 2: Tweet #3  â† Consumer est ici
  Offset 3: Tweet #4
```

Si le consumer s'arrÃªte et redÃ©marre, il reprend Ã  l'offset 2.

---

### Consumer Group

**DÃ©finition** : Groupe de consumers qui partagent la lecture d'un topic

**Exemple 1 - MÃªme groupe** :
```
Consumer A (group: 'team1') â†’ Lit 50% des messages
Consumer B (group: 'team1') â†’ Lit 50% des messages
```

**Exemple 2 - Groupes diffÃ©rents** :
```
Consumer A (group: 'team1') â†’ Lit 100% des messages
Consumer B (group: 'team2') â†’ Lit 100% des messages (indÃ©pendant)
```

---

### Auto-commit

**DÃ©finition** : Kafka sauvegarde automatiquement l'offset

**Avantage** : Si le consumer crash, il reprend oÃ¹ il en Ã©tait  
**InconvÃ©nient** : Peut perdre des messages si crash avant traitement

---

## ğŸ”— Ressources

- **Documentation Kafka** : [kafka.apache.org](https://kafka.apache.org/documentation/)
- **kafka-python** : [kafka-python.readthedocs.io](https://kafka-python.readthedocs.io/)
- **SchÃ©ma JSON** : [../docs/schema.json](../docs/schema.json)
- **Architecture** : [../docs/04-architecture.md](../docs/04-architecture.md)

---

## ğŸ“ Support

**ProblÃ¨mes avec le consumer ?**
- Consulter [../docs/03-troubleshooting.md](../docs/03-troubleshooting.md)
- VÃ©rifier que Docker tourne : `docker-compose ps`
- VÃ©rifier les logs Kafka : `docker logs kafka`

**Pour Personne 2** : Voir [../docs/05-handoff-to-person2.md](../docs/05-handoff-to-person2.md)

---

## âœ… Checklist

```
â˜ Docker Compose lancÃ© (docker-compose up -d)
â˜ Kafka dÃ©marrÃ© (docker logs kafka | grep "started")
â˜ venv activÃ© (source ../venv/bin/activate)
â˜ Topic existe (kafka-topics --list)
â˜ Producer lancÃ© (python ../producer/twitter_simulator.py)
â˜ Consumer lancÃ© (python consumer.py)
â˜ Les tweets s'affichent en temps rÃ©el
```

---

**Le consumer est la porte d'entrÃ©e vers l'analyse des donnÃ©es ! ğŸšªğŸ“Š**