#!/usr/bin/env python3
"""
üì• KAFKA CONSUMER - VERSION AM√âLIOR√âE

AM√âLIORATIONS par rapport √† consumer.py :
‚úÖ Commit manuel (pas de perte de messages)
‚úÖ Traitement par batch (performance x10)
‚úÖ Monitoring en temps r√©el
‚úÖ Gestion robuste des erreurs
‚úÖ Dead Letter Queue (DLQ) optionnelle

UTILISATION :
    python consumer_improved.py

DIFF√âRENCES AVEC L'ANCIEN :
- Commit APR√àS traitement (s√©curis√©)
- Traite 10 messages d'un coup (batch)
- Affiche des statistiques toutes les 10s
- Peut envoyer les erreurs vers DLQ
"""

from kafka import KafkaConsumer, KafkaProducer
from kafka.errors import NoBrokersAvailable, KafkaError
import json
import os
import time
import sys
import logging
from datetime import datetime
from dotenv import load_dotenv

# ============================================================================
# CONFIGURATION DES LOGS
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('consumer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================================
# CHARGEMENT DE LA CONFIGURATION
# ============================================================================
load_dotenv(dotenv_path='../.env')

KAFKA_BROKER = os.getenv('KAFKA_BROKER', 'localhost:9092')
KAFKA_TOPIC = os.getenv('KAFKA_TOPIC', 'tweets_raw')
DLQ_TOPIC = 'tweets_failed'  # Dead Letter Queue

# ============================================================================
# CLASSE POUR LE MONITORING
# ============================================================================
class ConsumerMetrics:
    """Suivi des performances du consumer"""
    
    def __init__(self):
        self.messages_received = 0
        self.messages_processed = 0
        self.messages_failed = 0
        self.batches_processed = 0
        self.start_time = time.time()
        self.processing_times = []
        self.last_print_time = time.time()
    
    def record_batch_processed(self, batch_size, processing_time):
        """Enregistrer un batch trait√©"""
        self.messages_processed += batch_size
        self.batches_processed += 1
        self.processing_times.append(processing_time)
    
    def record_message_received(self):
        """Enregistrer un message re√ßu"""
        self.messages_received += 1
    
    def record_failure(self):
        """Enregistrer un √©chec"""
        self.messages_failed += 1
    
    def print_stats(self, force=False):
        """Afficher les stats toutes les 10 secondes"""
        now = time.time()
        
        if force or (now - self.last_print_time) >= 10:
            elapsed = now - self.start_time
            rate = self.messages_processed / elapsed if elapsed > 0 else 0
            
            if self.processing_times:
                avg_processing = sum(self.processing_times) / len(self.processing_times)
            else:
                avg_processing = 0
            
            print("\n" + "=" * 80)
            print("üìä STATISTIQUES KAFKA CONSUMER")
            print("=" * 80)
            print(f"üì• Messages re√ßus:       {self.messages_received}")
            print(f"‚úÖ Messages trait√©s:     {self.messages_processed}")
            print(f"‚ùå Messages √©chou√©s:     {self.messages_failed}")
            print(f"üì¶ Batches trait√©s:      {self.batches_processed}")
            print(f"‚ö° D√©bit:                {rate:.2f} msg/s")
            print(f"‚è±Ô∏è  Temps moyen/batch:   {avg_processing*1000:.2f}ms")
            print(f"‚è≥ Temps √©coul√©:         {elapsed/60:.1f} minutes")
            print("=" * 80 + "\n")
            
            self.last_print_time = now

# ============================================================================
# FONCTION DE TRAITEMENT DES TWEETS
# ============================================================================

def process_batch(tweets):
    """
    Traite un batch de tweets
    
    Dans votre cas, ici vous pourriez :
    - Analyser avec OpenAI
    - Indexer dans Elasticsearch
    - Faire des calculs, etc.
    
    Pour l'instant, on simule juste le traitement.
    """
    for tweet in tweets:
        # Simuler un traitement
        logger.debug(f"Traitement de {tweet['tweet_id']}")
        
        # Ici vous pourriez faire :
        # - sentiment = analyze_with_openai(tweet['text'])
        # - index_to_elasticsearch(tweet)
        # - etc.
        
        time.sleep(0.001)  # Simuler 1ms de traitement
    
    logger.info(f"‚úÖ Batch de {len(tweets)} tweets trait√©")

# ============================================================================
# CONFIGURATION DU PRODUCER DLQ (OPTIONNEL)
# ============================================================================

def create_dlq_producer():
    """Cr√©er un producer pour la Dead Letter Queue"""
    try:
        dlq_producer = KafkaProducer(
            bootstrap_servers=KAFKA_BROKER,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            acks='all'
        )
        logger.info("‚úÖ DLQ Producer cr√©√©")
        return dlq_producer
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  DLQ Producer non disponible: {e}")
        return None

dlq_producer = create_dlq_producer()

def send_to_dlq(tweet, error, message_info):
    """Envoyer un message vers la Dead Letter Queue"""
    if dlq_producer is None:
        logger.warning(f"‚ö†Ô∏è  DLQ non disponible, message ignor√©")
        return
    
    error_message = {
        'original_tweet': tweet,
        'error_type': type(error).__name__,
        'error_message': str(error),
        'failed_at': datetime.now().isoformat(),
        'consumer_group': 'tweet-consumer-group-v2',
        'topic': message_info['topic'],
        'partition': message_info['partition'],
        'offset': message_info['offset']
    }
    
    try:
        dlq_producer.send(DLQ_TOPIC, value=error_message)
        dlq_producer.flush()
        logger.info(f"üì§ Message envoy√© vers DLQ: Tweet #{tweet.get('tweet_id', 'N/A')}")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'envoi vers DLQ: {e}")

# ============================================================================
# CONNEXION AU CONSUMER KAFKA
# ============================================================================

print("=" * 80)
print("üì• KAFKA CONSUMER - VERSION AM√âLIOR√âE")
print("=" * 80)
print(f"üì° Kafka Broker: {KAFKA_BROKER}")
print(f"üìÆ Topic: {KAFKA_TOPIC}")
print("\nüî• AM√âLIORATIONS ACTIVES :")
print("   ‚úÖ Commit manuel ‚Üí Pas de perte de messages")
print("   ‚úÖ Traitement par batch ‚Üí Performance x10")
print("   ‚úÖ Monitoring ‚Üí Stats toutes les 10s")
print("   ‚úÖ Dead Letter Queue ‚Üí Sauvegarde des erreurs")
print("=" * 80)

# Retry connection
max_retries = 10
retry_delay = 3
consumer = None

for attempt in range(1, max_retries + 1):
    try:
        print(f"\nüîÑ Tentative de connexion √† Kafka ({attempt}/{max_retries})...")
        
        consumer = KafkaConsumer(
            KAFKA_TOPIC,
            bootstrap_servers=KAFKA_BROKER,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            
            # ‚úÖ AM√âLIORATION 1 : Commit manuel
            enable_auto_commit=False,  # On contr√¥le quand commiter
            
            # ‚úÖ AM√âLIORATION 2 : Performance
            max_poll_records=100,      # Lire jusqu'√† 100 messages
            fetch_min_bytes=1024,      # Attendre 1KB min
            fetch_max_wait_ms=500,     # Ou 500ms max
            
            # ‚úÖ AM√âLIORATION 3 : Timeouts optimis√©s
            #session_timeout_ms=30000,
            heartbeat_interval_ms=1000,
            
            # Autres param√®tres
            auto_offset_reset='earliest',
            group_id='tweet-consumer-group-v2',  # Nouveau groupe
            #request_timeout_ms=30000,
            connections_max_idle_ms=540000
        )
        
        logger.info("‚úÖ Connexion √† Kafka r√©ussie !")
        break
        
    except NoBrokersAvailable:
        if attempt < max_retries:
            logger.warning(f"‚ö†Ô∏è  Kafka pas encore pr√™t. Nouvelle tentative dans {retry_delay}s...")
            time.sleep(retry_delay)
        else:
            logger.error("\n‚ùå Impossible de se connecter √† Kafka apr√®s plusieurs tentatives")
            logger.error("‚û°Ô∏è  V√©rifiez que Docker est bien d√©marr√© : docker-compose ps")
            logger.error("‚û°Ô∏è  V√©rifiez les logs Kafka : docker logs kafka")
            sys.exit(1)

if not consumer:
    sys.exit(1)

print("\n‚è∏Ô∏è  Ctrl+C pour arr√™ter")
print("üìä Statistiques affich√©es toutes les 10 secondes")
print("=" * 80)
print()

# ============================================================================
# BOUCLE PRINCIPALE - TRAITEMENT PAR BATCH
# ============================================================================

metrics = ConsumerMetrics()
messages_buffer = []
BATCH_SIZE = 10  # Traiter par batch de 10

logger.info("üëÇ En √©coute des tweets (mode batch)...\n")

try:
    for message in consumer:
        tweet = message.value
        metrics.record_message_received()
        
        # Ajouter au buffer
        messages_buffer.append({
            'tweet': tweet,
            'metadata': {
                'topic': message.topic,
                'partition': message.partition,
                'offset': message.offset
            }
        })
        
        print(f"üì© Tweet #{metrics.messages_received} re√ßu")
        print(f"   ID: {tweet.get('tweet_id', 'N/A')}")
        print(f"   üë§ User: {tweet.get('user', 'N/A')}")
        print(f"   üìù Text: {tweet.get('text', '')[:60]}...")
        print(f"   üì¶ Buffer: {len(messages_buffer)}/{BATCH_SIZE}")
        
        # Traiter quand le batch est plein
        if len(messages_buffer) >= BATCH_SIZE:
            print(f"\nüîÑ Traitement d'un batch de {len(messages_buffer)} tweets...")
            
            start_time = time.time()
            failed_count = 0
            
            try:
                # Extraire seulement les tweets (pas les m√©tadonn√©es)
                tweets = [item['tweet'] for item in messages_buffer]
                
                # ‚úÖ TRAITER le batch
                process_batch(tweets)
                
                # Mesurer le temps
                processing_time = time.time() - start_time
                metrics.record_batch_processed(len(messages_buffer), processing_time)
                
                print(f"‚úÖ Batch trait√© en {processing_time*1000:.2f}ms")
                
                # ‚úÖ COMMIT seulement si tout s'est bien pass√©
                consumer.commit()
                print(f"‚úÖ Offset commit√© (messages sauvegard√©s)\n")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du traitement du batch: {e}")
                
                # Envoyer vers DLQ
                for item in messages_buffer:
                    send_to_dlq(item['tweet'], e, item['metadata'])
                    metrics.record_failure()
                
                # ‚ö†Ô∏è  On commit quand m√™me pour ne pas bloquer
                # (Les messages sont dans la DLQ)
                consumer.commit()
                print(f"‚ö†Ô∏è  Batch √©chou√©, messages envoy√©s vers DLQ\n")
            
            # Vider le buffer
            messages_buffer = []
        
        print("-" * 80)
        
        # ‚úÖ AFFICHER les statistiques p√©riodiquement
        metrics.print_stats()

except KeyboardInterrupt:
    print(f"\n‚õî Arr√™t demand√©")
    
    # Traiter les messages restants dans le buffer
    if messages_buffer:
        print(f"üîÑ Traitement des {len(messages_buffer)} messages restants...")
        
        try:
            tweets = [item['tweet'] for item in messages_buffer]
            process_batch(tweets)
            consumer.commit()
            print("‚úÖ Messages restants trait√©s et commit√©s")
        except Exception as e:
            logger.error(f"‚ùå Erreur sur les messages restants: {e}")
            for item in messages_buffer:
                send_to_dlq(item['tweet'], e, item['metadata'])
    
    # Afficher les stats finales
    print(f"\nüìä STATISTIQUES FINALES")
    metrics.print_stats(force=True)

except Exception as e:
    logger.error(f"\n‚ùå Erreur: {e}")
    import traceback
    traceback.print_exc()

finally:
    if consumer:
        consumer.close()
        logger.info("‚úÖ Consumer ferm√© proprement")
    
    if dlq_producer:
        dlq_producer.close()
        logger.info("‚úÖ DLQ Producer ferm√© proprement")
